{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dacon_cv2_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNoRy7hyYcu0tKf3aq+9UR7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehddnr301/dacon_cv2/blob/master/dacon_cv2_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RlYIZQfZTvB",
        "outputId": "2949b8c0-d870-47d1-810f-f4a91f281484"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdzZBm_bZY_x",
        "outputId": "98ba672c-991e-4a41-8030-78e3cca5365b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Feb 18 09:45:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMngqCF4ZZB1",
        "outputId": "c58bb3f8-3f19-4d0d-c962-6a14114e2085"
      },
      "source": [
        "import os\n",
        "\n",
        "os.listdir('/content/drive/MyDrive/dacon_computer_vision/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data',\n",
              " 'Untitled1.ipynb',\n",
              " 'model.h5',\n",
              " 'eff_model.pt',\n",
              " 'eff_model1.pt',\n",
              " 'dacon-vision2.ipynb',\n",
              " 'Untitled0.ipynb',\n",
              " 'checkpoint',\n",
              " 'dacon_cv.zip',\n",
              " 'eff_model_cv2.pt',\n",
              " 'Untitled3.ipynb',\n",
              " 'Untitled2.ipynb',\n",
              " 'dacon_cv2.ipynb',\n",
              " 'eff_model_0214.pt',\n",
              " 'dacon_computervision2.ipynb',\n",
              " 'dacon_cv2_resnet.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB_0eX0CZZEQ",
        "outputId": "5994f834-8abe-48c0-edca-96d2c11506ef"
      },
      "source": [
        "# colab 에서 자꾸 unzip한 이미지중에 일부가 없어져서 -n modifier를 주고 계속 실행하려함.\n",
        "!unzip -n '/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist_2nd.zip' -d '/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist_2nd.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trwZinRAZZGw"
      },
      "source": [
        "!pip install torchinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1vPACcWZZJZ"
      },
      "source": [
        "import os\n",
        "from typing import Tuple, Sequence, Callable\n",
        "import csv\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "\n",
        "import albumentations\n",
        "\n",
        "\n",
        "from torchvision import transforms\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpN2LqCAZZLv"
      },
      "source": [
        "# random seed\n",
        "random_seed = 777\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "\n",
        "\n",
        "IMAGE_WIDTH=256\n",
        "IMAGE_HEIGHT=256\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "EPOCHS=30\n",
        "\n",
        "PATH_TRAIN_DATASET='/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist/'\n",
        "PATH_TEST_DATASET='/content/drive/MyDrive/dacon_computer_vision/data/test_dirty_mnist/'\n",
        "PATH_TRAIN_ANS_CSV='/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist_2nd_answer.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tQERW2JZZOg"
      },
      "source": [
        "df = pd.read_csv(PATH_TRAIN_ANS_CSV)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4lfSZbiZZQv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, valid = train_test_split(df, test_size=0.05, random_state=random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n1PM7r5ZZTb"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey9F8WlxZZWH"
      },
      "source": [
        "PATH_TRAIN_CSV='/content/drive/MyDrive/dacon_computer_vision/data/mnist_train.csv'\n",
        "PATH_VALID_CSV='/content/drive/MyDrive/dacon_computer_vision/data/mnist_valid.csv'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5OyK-S-ZZYx"
      },
      "source": [
        "train.to_csv(PATH_TRAIN_CSV, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96v7zNAdZZbZ"
      },
      "source": [
        "valid.to_csv(PATH_VALID_CSV, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyGEz624ZZeB"
      },
      "source": [
        "class MnistDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dir: os.PathLike,\n",
        "        image_ids: os.PathLike,\n",
        "        transforms: Sequence[Callable]\n",
        "    ) -> None:\n",
        "        self.dir = dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.labels = {}\n",
        "        with open(image_ids, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)\n",
        "            for row in reader:\n",
        "                self.labels[int(row[0])] = list(map(int, row[1:]))\n",
        "\n",
        "        self.image_ids = list(self.labels.keys())\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Tensor]:\n",
        "        image_id = self.image_ids[index]\n",
        "        image = cv2.imread(\n",
        "            os.path.join(\n",
        "                self.dir, f'{str(image_id).zfill(5)}.png'))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        target = np.array(self.labels.get(image_id)).astype(np.float32)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            augmented = self.transforms(image=image) \n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRKrMgJiZZgY"
      },
      "source": [
        "from albumentations.pytorch import ToTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubkixh8-ZZjK"
      },
      "source": [
        "transforms_train = albumentations.Compose([\n",
        "    albumentations.OneOf([\n",
        "                          albumentations.HorizontalFlip(p=1),\n",
        "                          albumentations.VerticalFlip(p=1),\n",
        "                          albumentations.RandomRotate90(p=0.5)\n",
        "    ], p=0.8),\n",
        "    albumentations.OneOf([\n",
        "                          albumentations.RandomBrightness(limit=0.1, p=1),\n",
        "                          albumentations.RandomContrast(limit=0.1, p=1),\n",
        "    ], p=0.7),\n",
        "    albumentations.OneOf([\n",
        "                          albumentations.Blur(p=1),\n",
        "                          albumentations.OpticalDistortion(p=1),\n",
        "                          albumentations.GaussNoise(p=1)                 \n",
        "    ], p=0.3),\n",
        "    ToTensor((\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )),\n",
        "])\n",
        "\n",
        "transforms_valid = albumentations.Compose([\n",
        "    albumentations.HorizontalFlip(p=0.5),\n",
        "    albumentations.VerticalFlip(p=0.5),\n",
        "    ToTensor((\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )),\n",
        "])\n",
        "\n",
        "transforms_test = albumentations.Compose([\n",
        "    ToTensor((\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTDzGj6_ZZl6"
      },
      "source": [
        "trainset = MnistDataset(PATH_TRAIN_DATASET, PATH_TRAIN_CSV, transforms_train)\n",
        "valset = MnistDataset(PATH_TRAIN_DATASET, PATH_VALID_CSV, transforms_valid)\n",
        "testset = MnistDataset(PATH_TEST_DATASET, '/content/drive/MyDrive/dacon_computer_vision/data/sample_submission.csv', transforms_test)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=512)\n",
        "val_loader = DataLoader(valset, batch_size=256)\n",
        "test_loader = DataLoader(testset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuiKPQsspGfr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEaEVPRjZZrh"
      },
      "source": [
        "!pip install nfnets-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqTgxfo5Z_GN"
      },
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "from nfnets import replace_conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8L1qVHcZZoq"
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.resnet = resnet18()\n",
        "        self.classifier = nn.Sequential(\n",
        "                            nn.Linear(512, 270),\n",
        "                            nn.PReLU(),\n",
        "                            nn.Linear(270,90),\n",
        "                            nn.PReLU(),\n",
        "                            nn.Linear(90,26)\n",
        "                          )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MnistModel()\n",
        "replace_conv(model)\n",
        "model = model.to(device)\n",
        "print(summary(model, input_size=(1, 3, 256, 256), verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YN9x6oaZZxT"
      },
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                  mode='min',\n",
        "                                                  factor=0.5,\n",
        "                                                  patience=2,)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "\n",
        "    for i, (images, targets) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            outputs = outputs > 0.5\n",
        "            acc = (outputs == targets).float().mean()\n",
        "            print(f'{epoch+1}: {loss.item():.5f}, {acc.item():.5f}')\n",
        "\n",
        "\n",
        "    valid_acc_list = []\n",
        "    with tqdm(val_loader,\n",
        "            total=val_loader.__len__(),\n",
        "            unit=\"batch\") as valid_bar:\n",
        "        for i, (images, targets) in enumerate(valid_bar):\n",
        "            valid_bar.set_description(f\"Valid Epoch {epoch + 1}\")\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # 모델의 dropoupt, batchnormalization를 eval모드로 설정\n",
        "            # .forward()에서 중간 노드의 gradient를 계산\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # validation loss만을 계산\n",
        "                probs  = model(images)\n",
        "                valid_loss = criterion(probs, targets)\n",
        "\n",
        "\n",
        "                # train accuracy 계산\n",
        "                probs  = probs.cpu().detach().numpy()\n",
        "                targets = targets.cpu().detach().numpy()\n",
        "                preds = probs > 0.5\n",
        "                batch_acc = (targets == preds).mean()\n",
        "                valid_acc_list.append(batch_acc)\n",
        "\n",
        "            valid_acc = np.mean(valid_acc_list)\n",
        "            valid_bar.set_postfix(valid_loss = valid_loss.item(),\n",
        "                                  valid_acc = valid_acc)\n",
        "\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, f'/content/drive/MyDrive/dacon_computer_vision/checkpoint/model_resnet_0218_{epoch + 1}.pt')\n",
        "    \n",
        "    print('------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUw4EwBHZZz_"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W9B9WRIZZ4-"
      },
      "source": [
        "torch.save(model, '/content/drive/MyDrive/dacon_computer_vision/resnet_model_0218.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyBgXVzlZZ76"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB7G8eRKZZ-i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEcuZ_liZaBI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}