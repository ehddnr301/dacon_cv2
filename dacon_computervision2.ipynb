{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dacon_computervision2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOdhlYmbjJ0vn9QWCbOnsPb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehddnr301/dacon_cv2/blob/master/dacon_computervision2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac-z33XzoSJl",
        "outputId": "17890e63-2016-4358-bb23-f42156342ced"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UimgdZ8woT33",
        "outputId": "7c9ec731-c68b-4df2-f661-de02ddca2797"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb 15 01:30:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl6ilKuvoT6l",
        "outputId": "9325d1ff-637e-47bd-8e4f-55cba6660c17"
      },
      "source": [
        "import os\n",
        "\n",
        "os.listdir('/content/drive/MyDrive/dacon_computer_vision/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data',\n",
              " 'Untitled1.ipynb',\n",
              " 'model.h5',\n",
              " 'eff_model.pt',\n",
              " 'eff_model1.pt',\n",
              " 'dacon-vision2.ipynb',\n",
              " 'Untitled0.ipynb',\n",
              " 'checkpoint',\n",
              " 'dacon_cv.zip',\n",
              " 'eff_model_cv2.pt',\n",
              " 'Untitled3.ipynb',\n",
              " 'Untitled2.ipynb',\n",
              " 'dacon_cv2.ipynb',\n",
              " 'eff_model_0214.pt',\n",
              " 'dacon_computervision2.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IJm71u1oiru"
      },
      "source": [
        "# !unzip -n '/content/drive/MyDrive/dacon_computer_vision/dacon_cv.zip' -d '/content/drive/MyDrive/dacon_computer_vision/data/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NsKKcnCoT9N",
        "outputId": "acda96a4-33a4-4a1b-b5b6-d5502a9b4329"
      },
      "source": [
        "# colab 에서 자꾸 unzip한 이미지중에 일부가 없어져서 -n modifier를 주고 계속 실행하려함.\n",
        "!unzip -n '/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist_2nd.zip' -d '/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist_2nd.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpVC44jrUQv"
      },
      "source": [
        "!pip install torchinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AzgTOkpo2jb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNY_Sw9krXTK"
      },
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uTezMWArVk_"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-omTYMEzrQJs"
      },
      "source": [
        "import os\n",
        "from typing import Tuple, Sequence, Callable\n",
        "import csv\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchinfo import summary\n",
        "\n",
        "import albumentations\n",
        "\n",
        "\n",
        "from torchvision import transforms\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08caTzXC-wXO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fF0wLzbrKA5"
      },
      "source": [
        "# random seed\n",
        "random_seed = 777\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "\n",
        "\n",
        "IMAGE_WIDTH=256\n",
        "IMAGE_HEIGHT=256\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "EPOCHS=40\n",
        "\n",
        "PATH_TRAIN_DATASET='/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist/'\n",
        "PATH_TEST_DATASET='/content/drive/MyDrive/dacon_computer_vision/data/test_dirty_mnist/'\n",
        "PATH_TRAIN_ANS_CSV='/content/drive/MyDrive/dacon_computer_vision/data/dirty_mnist_2nd_answer.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA_ToJS57TFj"
      },
      "source": [
        "df = pd.read_csv(PATH_TRAIN_ANS_CSV)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DadKxZfH0_E8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeS1MNGg76YM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, valid = train_test_split(df, test_size=0.05, random_state=random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB3NteQXHyhE"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0eqQwLr8pV4"
      },
      "source": [
        "PATH_TRAIN_CSV='/content/drive/MyDrive/dacon_computer_vision/data/mnist_train.csv'\n",
        "PATH_VALID_CSV='/content/drive/MyDrive/dacon_computer_vision/data/mnist_valid.csv'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx4nguoq76aj"
      },
      "source": [
        "train.to_csv(PATH_TRAIN_CSV, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyFPxTi76c5"
      },
      "source": [
        "valid.to_csv(PATH_VALID_CSV, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CJo5pRJoT_1"
      },
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "mnist_sample = random.sample(os.listdir(PATH_TRAIN_DATASET), 10)\n",
        "\n",
        "for i, image in enumerate(mnist_sample):\n",
        "  path = os.path.join(PATH_TRAIN_DATASET, image)\n",
        "  img = Image.open(path)\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(img)\n",
        "  plt.xlabel('mnist')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "plt.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HyZpM01oUCV"
      },
      "source": [
        "class MnistDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dir: os.PathLike,\n",
        "        image_ids: os.PathLike,\n",
        "        transforms: Sequence[Callable]\n",
        "    ) -> None:\n",
        "        self.dir = dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        self.labels = {}\n",
        "        with open(image_ids, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)\n",
        "            for row in reader:\n",
        "                self.labels[int(row[0])] = list(map(int, row[1:]))\n",
        "\n",
        "        self.image_ids = list(self.labels.keys())\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Tensor]:\n",
        "        image_id = self.image_ids[index]\n",
        "        image = Image.open(\n",
        "            os.path.join(\n",
        "                self.dir, f'{str(image_id).zfill(5)}.png')).convert('RGB')\n",
        "        target = np.array(self.labels.get(image_id)).astype(np.float32)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            augmented = self.transform(image=image) \n",
        "            image = augmented['image']\n",
        "            \n",
        "        return image, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKVqqeXboUE-"
      },
      "source": [
        "transforms_train = albumentations.Compose([\n",
        "    albumentations.HorizontalFlip(p=0.5),\n",
        "    albumentations.VerticalFlip(p=0.5),\n",
        "    albumentations.ShiftScaleRotate(p=0.5,rotate_limit=180),\n",
        "    albumentations.OneOf([\n",
        "                          albumentations.RandomBrightness(limit=0.1),\n",
        "                          albumentations.RandomContrast(),\n",
        "                          albumentations.Blur()\n",
        "    ])\n",
        "    albumentations.CenterCrop(240,240,p=0.3),\n",
        "    albumentations.pytorch.transforms.ToTensorV2(),\n",
        "    albumentations.augmentations.transforms.Normalize()\n",
        "])\n",
        "\n",
        "transforms_valid = albumentations.Compose([\n",
        "    albumentations.HorizontalFlip(p=0.5),\n",
        "    albumentations.VerticalFlip(p=0.5),\n",
        "    albumentations.pytorch.transforms.ToTensorV2(),\n",
        "    albumentations.augmentations.transforms.Normalize()\n",
        "])\n",
        "\n",
        "transforms_test = albumentations.Compose([\n",
        "    albumentations.pytorch.transforms.ToTensorV2(),\n",
        "    albumentations.augmentations.transforms.Normalize()\n",
        "])\n",
        "\n",
        "\n",
        "# transforms_train = transforms.Compose([\n",
        "#     transforms.RandomHorizontalFlip(p=0.5),\n",
        "#     transforms.RandomVerticalFlip(p=0.5),\n",
        "#     transforms.RandomRotation(degrees=(180, 180)),\n",
        "#     transforms.RandomAffine(5),\n",
        "#     transforms.RandomGrayscale(p=0.5),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(\n",
        "#         [0.485, 0.456, 0.406],\n",
        "#         [0.229, 0.224, 0.225]\n",
        "#     )\n",
        "# ])\n",
        "\n",
        "# transforms_valid = transforms.Compose([\n",
        "#     transforms.RandomHorizontalFlip(p=0.5),\n",
        "#     transforms.RandomVerticalFlip(p=0.5),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(\n",
        "#         [0.485, 0.456, 0.406],\n",
        "#         [0.229, 0.224, 0.225]\n",
        "#     )\n",
        "# ])\n",
        "\n",
        "# transforms_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(\n",
        "#         [0.485, 0.456, 0.406],\n",
        "#         [0.229, 0.224, 0.225]\n",
        "#     )\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3Khp3FiQczk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L31ZneFzbq3g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxDSLim2oUHZ"
      },
      "source": [
        "trainset = MnistDataset(PATH_TRAIN_DATASET, PATH_TRAIN_CSV, transforms_train)\n",
        "valset = MnistDataset(PATH_TRAIN_DATASET, PATH_VALID_CSV, transforms_valid)\n",
        "testset = MnistDataset(PATH_TEST_DATASET, '/content/drive/MyDrive/dacon_computer_vision/data/sample_submission.csv', transforms_test)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=32)\n",
        "val_loader = DataLoader(valset, batch_size=32)\n",
        "test_loader = DataLoader(testset, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyWeKiw7QpYy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZGKbMEHZNy"
      },
      "source": [
        "# print(valset.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0obXaGKoUKk"
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.effnet = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "        self.classifier = nn.Linear(1000, 26)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.effnet(x)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MnistModel().to(device)\n",
        "print(summary(model, input_size=(1, 3, 256, 256), verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5j-FPrToUM9"
      },
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                  mode='min',\n",
        "                                                  factor=0.5,\n",
        "                                                  patience=2,)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "\n",
        "    for i, (images, targets) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            outputs = outputs > 0.5\n",
        "            acc = (outputs == targets).float().mean()\n",
        "            print(f'{epoch+1}: {loss.item():.5f}, {acc.item():.5f}')\n",
        "\n",
        "\n",
        "    valid_acc_list = []\n",
        "    with tqdm(val_loader,\n",
        "            total=val_loader.__len__(),\n",
        "            unit=\"batch\") as valid_bar:\n",
        "        for i, (images, targets) in enumerate(valid_bar):\n",
        "            valid_bar.set_description(f\"Valid Epoch {epoch + 1}\")\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # 모델의 dropoupt, batchnormalization를 eval모드로 설정\n",
        "            # .forward()에서 중간 노드의 gradient를 계산\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # validation loss만을 계산\n",
        "                probs  = model(images)\n",
        "                valid_loss = criterion(probs, targets)\n",
        "\n",
        "\n",
        "                # train accuracy 계산\n",
        "                probs  = probs.cpu().detach().numpy()\n",
        "                targets = targets.cpu().detach().numpy()\n",
        "                preds = probs > 0.5\n",
        "                batch_acc = (targets == preds).mean()\n",
        "                valid_acc_list.append(batch_acc)\n",
        "\n",
        "            valid_acc = np.mean(valid_acc_list)\n",
        "            valid_bar.set_postfix(valid_loss = valid_loss.item(),\n",
        "                                  valid_acc = valid_acc)\n",
        "\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, f'/content/drive/MyDrive/dacon_computer_vision/checkpoint/model_0214_{epoch + 1}.pt')\n",
        "    \n",
        "    print('------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwAJMLFTvjk0"
      },
      "source": [
        "torch.save(model, '/content/drive/MyDrive/dacon_computer_vision/eff_model_0215.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0RZTzu60vFX"
      },
      "source": [
        "# 중간에 학습이 종료되어서 6번째 epoch을 불러와서 predict에 사용\n",
        "\n",
        "# PATH = '/content/drive/MyDrive/dacon_computer_vision/checkpoint/model_0214_20.pt'\n",
        "# model = MnistModel().to(device)\n",
        "\n",
        "# checkpoint = torch.load(PATH)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHJP9C94vlna"
      },
      "source": [
        "!unzip -n '/content/drive/MyDrive/dacon_computer_vision/data/test_dirty_mnist_2nd.zip' -d '/content/drive/MyDrive/dacon_computer_vision/data/test_dirty_mnist'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rakGv5xVcbNZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIKR7dAmvrKz"
      },
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_computer_vision/data/sample_submission.csv')\n",
        "\n",
        "model.eval()\n",
        "batch_size = test_loader.batch_size\n",
        "batch_index = 0\n",
        "for i, (images, targets) in enumerate(test_loader):\n",
        "    images = images.to(device)\n",
        "    targets = targets.to(device)\n",
        "    outputs = model(images)\n",
        "    outputs = outputs > 0.5\n",
        "    batch_index = i * batch_size\n",
        "    submit.iloc[batch_index:batch_index+batch_size, 1:] = \\\n",
        "        outputs.long().squeeze(0).detach().cpu().numpy()\n",
        "    \n",
        "submit.to_csv('/content/drive/MyDrive/dacon_computer_vision/data/submit0215.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-pHC-2P1RP-"
      },
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                  mode='min',\n",
        "                                                  factor=0.5,\n",
        "                                                  patience=2,)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    \n",
        "\n",
        "    for i, (images, targets) in enumerate(val_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            outputs = outputs > 0.5\n",
        "            acc = (outputs == targets).float().mean()\n",
        "            print(f'{epoch+1}: {loss.item():.5f}, {acc.item():.5f}')\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, f'/content/drive/MyDrive/dacon_computer_vision/checkpoint/model_0215_{epoch + 1}.pt')\n",
        "    \n",
        "    print('------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9DMScEk72gq"
      },
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dacon_computer_vision/data/sample_submission.csv')\n",
        "\n",
        "model.eval()\n",
        "batch_size = test_loader.batch_size\n",
        "batch_index = 0\n",
        "for i, (images, targets) in enumerate(test_loader):\n",
        "    images = images.to(device)\n",
        "    targets = targets.to(device)\n",
        "    outputs = model(images)\n",
        "    outputs = outputs > 0.5\n",
        "    batch_index = i * batch_size\n",
        "    submit.iloc[batch_index:batch_index+batch_size, 1:] = \\\n",
        "        outputs.long().squeeze(0).detach().cpu().numpy()\n",
        "    \n",
        "submit.to_csv('/content/drive/MyDrive/dacon_computer_vision/data/submit0215_after_valid.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK9i-IqFCt8V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}